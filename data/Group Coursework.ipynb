{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f765c74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4514ccce",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "135f2c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates: 0\n",
      "Missing: 103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25212/158455082.py:5: UserWarning: Parsing dates in %d-%m-%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"/workspaces/python-for-finance-bobby-zlatarov/DASH.csv\")\n",
    "\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "df = df.set_index(\"Date\").sort_index().drop_duplicates()\n",
    "\n",
    "print(\"Duplicates:\", df.duplicated().sum())\n",
    "print(\"Missing:\", df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad91e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### missing values blah balh \n",
    "\n",
    "# OPen Prices:\n",
    "df[\"Prev\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32135358",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bd010c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1482f181",
   "metadata": {},
   "source": [
    "## KEY DATES\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af34ae0c",
   "metadata": {},
   "source": [
    "## Highest Rolling Volatility dates\n",
    "\n",
    "To identify the date and the value of the highest rolling volatility in each year, we are using the `groupby` function to group the data by the different years for which we also need the `to_period` function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b27f9d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22628/3179754162.py:1: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  df['DailyReturn'] = df['Close'].pct_change()\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'DataFrame'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[32m/tmp/ipykernel_22628/3179754162.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      4\u001b[39m \n\u001b[32m      5\u001b[39m \n\u001b[32m      6\u001b[39m df[\u001b[33m\"Year\"\u001b[39m] = df.index.to_period(\u001b[33m\"Y\"\u001b[39m)\n\u001b[32m      7\u001b[39m \n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m df.loc[df.dropna(subset=[\u001b[33m'RollingVolatility'\u001b[39m]).groupby(\u001b[33m\"Year\"\u001b[39m).RollingVolatility.idxmax]\n\u001b[32m      9\u001b[39m \n\u001b[32m     10\u001b[39m \n\u001b[32m     11\u001b[39m df.groupby(df.Year).RollingVolatility.max()\n",
      "\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/indexing.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1185\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1186\u001b[39m             \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[32m   1187\u001b[39m             axis = self.axis \u001b[38;5;28;01mor\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m   1188\u001b[39m \n\u001b[32m-> \u001b[39m\u001b[32m1189\u001b[39m             maybe_callable = com.apply_if_callable(key, self.obj)\n\u001b[32m   1190\u001b[39m             maybe_callable = self._check_deprecated_callable_usage(key, maybe_callable)\n\u001b[32m   1191\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self._getitem_axis(maybe_callable, axis=axis)\n",
      "\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/common.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(maybe_callable, obj, **kwargs)\u001b[39m\n\u001b[32m    380\u001b[39m     obj : NDFrame\n\u001b[32m    381\u001b[39m     **kwargs\n\u001b[32m    382\u001b[39m     \"\"\"\n\u001b[32m    383\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m callable(maybe_callable):\n\u001b[32m--> \u001b[39m\u001b[32m384\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m maybe_callable(obj, **kwargs)\n\u001b[32m    385\u001b[39m \n\u001b[32m    386\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m maybe_callable\n",
      "\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/groupby/generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, axis, skipna)\u001b[39m\n\u001b[32m   1182\u001b[39m     @doc(Series.idxmax.__doc__)\n\u001b[32m   1183\u001b[39m     def idxmax(\n\u001b[32m   1184\u001b[39m         self, axis: Axis | lib.NoDefault = lib.no_default, skipna: bool = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1185\u001b[39m     ) -> Series:\n\u001b[32m-> \u001b[39m\u001b[32m1186\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m self._idxmax_idxmin(\u001b[33m\"idxmax\"\u001b[39m, axis=axis, skipna=skipna)\n",
      "\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/groupby/groupby.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, how, ignore_unobserved, axis, skipna, numeric_only)\u001b[39m\n\u001b[32m   5822\u001b[39m         \"\"\"\n\u001b[32m   5823\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m lib.no_default:\n\u001b[32m   5824\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5825\u001b[39m                 axis = self.axis\n\u001b[32m-> \u001b[39m\u001b[32m5826\u001b[39m             axis = self.obj._get_axis_number(axis)\n\u001b[32m   5827\u001b[39m             self._deprecate_axis(axis, how)\n\u001b[32m   5828\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   5829\u001b[39m             axis = self.axis\n",
      "\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(cls, axis)\u001b[39m\n\u001b[32m    573\u001b[39m     @classmethod\n\u001b[32m    574\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m _get_axis_number(cls, axis: Axis) -> AxisInt:\n\u001b[32m    575\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    576\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m cls._AXIS_TO_AXIS_NUMBER[axis]\n\u001b[32m--> \u001b[39m\u001b[32m577\u001b[39m         \u001b[38;5;28;01mexcept\u001b[39;00m KeyError:\n\u001b[32m    578\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m ValueError(f\"No axis named {axis} for object type {cls.__name__}\")\n",
      "\u001b[31mTypeError\u001b[39m: unhashable type: 'DataFrame'"
     ]
    }
   ],
   "source": [
    "df['DailyReturn'] = df['Close'].pct_change()\n",
    "df.dropna\n",
    "df['RollingVolatility'] = df['DailyReturn'].rolling(window=20).std()\n",
    "\n",
    "\n",
    "df[\"Year\"] = df.index.to_period(\"Y\")\n",
    "\n",
    "df.loc[df.dropna(subset=['RollingVolatility']).groupby(\"Year\").RollingVolatility.idxmax]\n",
    "\n",
    "\n",
    "df.groupby(df.Year).RollingVolatility.max()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fa1a1e",
   "metadata": {},
   "source": [
    "## Largest Price Surge Day:\n",
    "\n",
    "Similarly we also will use the `groupby` function to find greatest positive daily return each year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74ada8b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
